{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "- Dataset from https://github.com/ieee8023/covid-chestxray-dataset\n",
    "- COVID-19 Detector code from https://github.com/JordanMicahBennett/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --ignore-installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#to suppress un-necessary warnings\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, r2_score, classification_report, confusion_matrix\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Input, BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import keras\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = '../input/chest-xray-pneumonia/chest_xray/chest_xray/'\n",
    "# for root, dirs, files in os.walk(input_path_b):\n",
    "#     print(root, dirs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(img_dir, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(img_dir, 'val/NORMAL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory structure\n",
    "- img_dir\n",
    "    - train\n",
    "        - PNEUMONIA\n",
    "        - NORMAL\n",
    "    - val\n",
    "        - PNEUMONIA\n",
    "        - NORMAL\n",
    "    - test\n",
    "        - PNEUMONIA\n",
    "        - NORMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility\n",
    "seed = 232\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Hyperparameters\n",
    "img_size = 150\n",
    "batch_size = 8\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generators(img_dir, batch_size, img_size):\n",
    "    \"\"\"\n",
    "    This function will return two generators for train and val\n",
    "    And the test data \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    For the generator we could use tf.keras.preprocessing.image_dataset_from_directory \n",
    "    but this does not provide augmentation on the fly\n",
    "    \"\"\"\n",
    "    train_gen = ImageDataGenerator(rescale=1./255, vertical_flip=True, zoom_range=0.3)\n",
    "    val_test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = val_generator = None\n",
    "    \n",
    "    if os.path.isdir(os.path.join(img_dir, 'train')):\n",
    "        train_generator = train_gen.flow_from_directory(\n",
    "            os.path.join(img_dir, 'train'),\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size, \n",
    "            class_mode='binary')\n",
    "    if os.path.isdir(os.path.join(img_dir, 'val')):\n",
    "        val_generator = val_test_gen.flow_from_directory(\n",
    "            os.path.join(img_dir, 'val'),\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size, \n",
    "            class_mode='binary')\n",
    "    \n",
    "    test_imgs = []\n",
    "    test_targets = []\n",
    "    dirs = ['NORMAL', 'PNEUMONIA']\n",
    "    im=0\n",
    "    for dir_ in dirs:\n",
    "        for img in os.listdir(os.path.join(img_dir,'test', dir_)):\n",
    "            im = load_img(os.path.join(img_dir,'test', dir_,img), target_size=(img_size, img_size))\n",
    "            im = img_to_array(im)\n",
    "            im = im.astype('float')/255\n",
    "            test_imgs.append(im)\n",
    "            if dir_== 'NORMAL':\n",
    "                test_targets.append(0)\n",
    "            else:\n",
    "                test_targets.append(1)\n",
    "    return train_generator, val_generator, np.array(test_imgs), np.array(test_targets)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, val_generator, test_imgs, test_targets = get_data_generators(img_dir, batch_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T19:24:29.222882Z",
     "iopub.status.busy": "2022-01-05T19:24:29.222166Z",
     "iopub.status.idle": "2022-01-05T19:24:29.231256Z",
     "shell.execute_reply": "2022-01-05T19:24:29.230444Z",
     "shell.execute_reply.started": "2022-01-05T19:24:29.222829Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu', padding='same', input_shape=(img_size, img_size, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, 3, 3, activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, 3, 3, activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lung Pneumonia Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam()\n",
    "checkpoint = ModelCheckpoint(filepath='model.h5', save_best_only=True, save_weights_only=False)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss',patience=5, mode='min') #In 'min' mode, the learning rate will be reduced when the quantity monitored has stopped decreasing\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min')# it stops when the quantity monitored has stopped decreasing\n",
    "\n",
    "model = build_model(img_size)\n",
    "print(model.summary())\n",
    "model.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples//batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size, callbacks=[checkpoint, lr_reduce, early_stop], verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test_imgs)):\n",
    "    preds.append(np.round(model.predict(test_imgs[i].reshape(1, img_size, img_size, 3)))[0][0])\n",
    "print(\"Confusion matrix is:\\n\", confusion_matrix(np.array(preds), test_targets))\n",
    "print(classification_report(np.array(preds), test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID-19 Lung Pneumonia Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_covid = '../input/covid19-xray-dataset-train-test-sets/xray_dataset_covid19/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_train_generator, covid_val_generator, covid_test_imgs, covid_test_targets = get_data_generators(img_dir_covid, batch_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(img_dir_covid+'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = [test_imgs, covid_test_imgs]\n",
    "fig, axs = plt.subplots(2, 5, figsize=(18,4))\n",
    "fig.suptitle(\"First row: chest-xray-pneumonia\\n Second row: covid19-xray-dataset\")\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ind = random.randint(0, len(test_sets[i]))\n",
    "        axs[i][j].imshow(test_sets[i][ind])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: using the pretrained model for this new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidmodel = build_model(img_size)\n",
    "covidmodel.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "covidmodel.load_weights('model.h5')\n",
    "\n",
    "covid_preds = []\n",
    "for i in range(len(covid_test_imgs)):\n",
    "    covid_preds.append(np.round(model.predict(covid_test_imgs[i].reshape(1, img_size, img_size, 3)))[0][0])\n",
    "print(confusion_matrix(np.array(covid_preds), covid_test_targets))\n",
    "print(classification_report(np.array(covid_preds), covid_test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second: finetuning the last layers of the model for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-06T00:51:48.023246Z",
     "iopub.status.busy": "2022-01-06T00:51:48.022831Z",
     "iopub.status.idle": "2022-01-06T00:51:49.219175Z",
     "shell.execute_reply": "2022-01-06T00:51:49.218044Z",
     "shell.execute_reply.started": "2022-01-06T00:51:48.023194Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='covid_model.h5', save_best_only=True, save_weights_only=False)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss',patience=5, mode='min') #In 'min' mode, the learning rate will be reduced when the quantity monitored has stopped decreasing\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min')# it stops when the quantity monitored has stopped decreasing\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, # 1e-2\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optim = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "last_few_layers = 5\n",
    "for layer in covidmodel.layers[:-last_few_layers]:\n",
    "    layer.trainable = False\n",
    "# for l in covidmodel.layers:\n",
    "#     print(l.name, l.trainable)\n",
    "covidmodel.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_covid = covidmodel.fit(\n",
    "    covid_train_generator,\n",
    "    steps_per_epoch = covid_train_generator.samples//batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[checkpoint, lr_reduce, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(history_covid.history[met])\n",
    "    #ax[i].plot(history_covid.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    #ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_preds = []\n",
    "for i in range(len(covid_test_imgs)):\n",
    "    covid_preds.append(np.round(covidmodel.predict(covid_test_imgs[i].reshape(1, img_size, img_size, 3)))[0][0])\n",
    "print(confusion_matrix(np.array(covid_preds), covid_test_targets))\n",
    "print(classification_report(np.array(covid_preds), covid_test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate, decay_steps, alpha=0.0, name=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Joseph Paul Cohen and Paul Morrison and Lan Dao. COVID-19 image data collection, arXiv, 2020. https://github.com/ieee8023/covid-chestxray-dataset\n",
    "\n",
    "[2] https://github.com/JordanMicahBennett/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
